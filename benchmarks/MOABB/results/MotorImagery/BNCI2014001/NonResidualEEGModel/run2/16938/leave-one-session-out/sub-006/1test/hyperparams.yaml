# Generated 2024-04-20 from:
# /home/maianh/432/432/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/NonResidualEEGModel.yaml
# yamllint disable
seed: 16938
__set_torchseed: !apply:torch.manual_seed [16938]

# DIRECTORIES
data_folder: eeg_data
                           #'/path/to/dataset'. The dataset will be automatically downloaded in this folder
cached_data_folder: eeg_data/pkl
                                 #'path/to/pickled/dataset'
output_folder: results/MotorImagery/BNCI2014001/NonResidualEEGModel/run2/16938
                            #'path/to/results'

# DATASET HPARS
# Defining the MOABB dataset.
dataset: !new:moabb.datasets.BNCI2014_001
save_prepared_dataset: true # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards
data_iterator_name: leave-one-session-out
target_subject_idx: 5
target_session_idx: 1
events_to_load:      # all events will be loaded
original_sample_rate: 250 # Original sampling rate provided by dataset authors
sample_rate: 125 # Target sampling rate (Hz)
# band-pass filtering cut-off frequencies
fmin: 0.13
fmax: 46.0
n_classes: 4
# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class
# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long
# dataset interval starts from 2
# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)
tmin: 0.
tmax: 4.0
# number of steps used when selecting adjacent channels from a seed channel (default at Cz)
n_steps_channel_selection: 2
T: 500
C: 17
# We here specify how to perfom test:
# - If test_with: 'last' we perform test with the latest model.
# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)
# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.
# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.
test_with: last   # 'last' or 'best'
test_key: acc   # Possible opts: "loss", "f1", "auc", "acc"

# METRICS
f1: &id001 !name:sklearn.metrics.f1_score
  average: macro
acc: &id002 !name:sklearn.metrics.balanced_accuracy_score
cm: &id003 !name:sklearn.metrics.confusion_matrix
# TRAINING HPARS
metrics:
  f1: *id001
  acc: *id002
  cm: *id003
n_train_examples: 232  # it will be replaced in the train script
# checkpoints to average
avg_models: 10
number_of_epochs: 750
lr: 0.0001
weight_decay: 0.00001
# Learning rate scheduling (cyclic learning rate is used here)
max_lr: 0.0001    # Upper bound of the cycle (max value of the lr)
momentum: 0.9
base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)
step_size_multiplier: 5
step_size: &id004 !apply:round
- 11.6
lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler
  base_lr: 0.00000001
  max_lr: 0.0001
  step_size: *id004
label_smoothing: 0.0
loss: !name:speechbrain.nnet.losses.nll_loss
  label_smoothing: 0.0
optimizer: !name:torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.00001

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
                                                               # epoch counter
  limit: 750
batch_size_exponent: 4
batch_size: 100
valid_ratio: 0.2

# DATA AUGMENTATION
# cutcat (disabled when min_num_segments=max_num_segments=1)
max_num_segments: 3
cutcat: &id007 !new:speechbrain.augment.time_domain.CutCat
  min_num_segments: 2
  max_num_segments: 3
# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)
amp_delta: 0.01742
rand_amp: &id008 !new:speechbrain.augment.time_domain.RandAmp
  amp_low: 0.98258
  amp_high: 1.01742
# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)
shift_delta_: 1
shift_delta: 0.01                       # 0.250 # 0.-0.25 with steps of 0.01
min_shift: &id005 !apply:math.floor
- -1.25
max_shift: &id006 !apply:math.floor
- 1.25
time_shift: &id009 !new:speechbrain.augment.freq_domain.RandomShift
  min_shift: *id005
  max_shift: *id006
  dim: 1
# injection of gaussian white noise
snr_white_low: 15.0
snr_white_delta: 19.1
snr_white_high: 34.1
add_noise_white: &id010 !new:speechbrain.augment.time_domain.AddNoise
  snr_low: 15.0
  snr_high: 34.1

repeat_augment: 1 # @orion_step1: --repeat_augment 0
augment: !new:speechbrain.augment.augmenter.Augmenter
  parallel_augment: true
  concat_original: true
  parallel_augment_fixed_bs: true
  repeat_augment: 1
  shuffle_augmentations: true
  min_augmentations: 4
  max_augmentations: 4
  augmentations: [*id007, *id008, *id009, *id010]

# DATA NORMALIZATION
dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)
normalize: !name:speechbrain.processing.signal_processing.mean_std_norm
  dims: 1


# MODEL
input_shape: &id011 [null, 500, 17, null]
F1: 8
D: 2
conv_module0_cnn0_kernelsizes: 63 # @orion_step1: --conv_module0_cnn0_kernelsizes~"choices([41, 55, 61, 63])"
conv_module1_cnn0_kernelsizes: 51 # @orion_step1: --conv_module1_cnn0_kernelsizes~"choices([1, 55, 61, 63])"
conv_module2_cnn0_kernelsizes: 63 # @orion_step1: --conv_module2_cnn0_kernelsizes~"choices([41, 55, 61, 63])"
conv_depthwise_kernelsizes: 15 # @orion_step1: --conv_depthwise_kernelsizes~"choices([41, 55, 61, 63])"
classification_module_cnn_kernelsizes: 23 # @orion_step1: --classification_module_cnn_kernelsizes~"choices([5, 30, 41])"
avg_pool_kernels: 4 # @orion_step1: --avg_pool_kernels~"uniform(1, 8,discrete=True)"
conv_module4_avg_pool_kernels: 8 # @orion_step1: --conv_module4_avg_pool_kernels~"choices([4, 8])"
cnn_pool_type: avg
dropout: 0.25 # @orion_step1: --dropout~"choices([0.25, 0.5])"
activation_type: elu

model: !new:models.NonResidualEEGModel.NonResidualEEGModel
  input_shape: *id011
  F1: 8
  D: 2
  conv_module0_cnn0_kernelsizes: [1, 63]
  conv_module1_cnn0_kernelsizes: [1, 51]
  conv_module2_cnn0_kernelsizes: [63, 1]
  conv_depthwise_kernelsizes: [1, 15]
  classification_module_cnn_kernelsizes: [1, 23]
  avg_pool_kernels: [4, 1]
  conv_module4_avg_pool_kernels: [8, 1]
  cnn_pool_type: avg
  dropout: 0.25
  activation_type: elu

