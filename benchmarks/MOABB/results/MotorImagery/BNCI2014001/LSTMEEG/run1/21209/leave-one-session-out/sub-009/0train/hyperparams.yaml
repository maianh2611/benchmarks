# Generated 2024-04-23 from:
# /home/luc/MaiAnCut/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/LSTMEEG.yaml
# yamllint disable
seed: 21209
__set_torchseed: !apply:torch.manual_seed [21209]

# DIRECTORIES
data_folder: eeg_data
                           #'/path/to/dataset'. The dataset will be automatically downloaded in this folder
cached_data_folder: eeg_data/pkl
                                 #'path/to/pickled/dataset'
output_folder: results/MotorImagery/BNCI2014001/LSTMEEG/run1/21209
                            #'path/to/results'

# DATASET HPARS
# Defining the MOABB dataset.
dataset: !new:moabb.datasets.BNCI2014_001
save_prepared_dataset: true # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards
data_iterator_name: leave-one-session-out
target_subject_idx: 8
target_session_idx: 0
events_to_load:      # all events will be loaded
original_sample_rate: 250 # Original sampling rate provided by dataset authors
sample_rate: 125 # Target sampling rate (Hz)
# band-pass filtering cut-off frequencies
fmin: 0.13
fmax: 46.0
n_classes: 4
# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class
# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long
# dataset interval starts from 2
# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)
tmin: 0.
tmax: 4.0
# number of steps used when selecting adjacent channels from a seed channel (default at Cz)
n_steps_channel_selection: 2
T: 500
C: 17
# We here specify how to perfom test:
# - If test_with: 'last' we perform test with the latest model.
# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)
# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.
# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.
test_with: last   # 'last' or 'best'
test_key: acc   # Possible opts: "loss", "f1", "auc", "acc"

# METRICS
f1: &id001 !name:sklearn.metrics.f1_score
  average: macro
acc: &id002 !name:sklearn.metrics.balanced_accuracy_score
cm: &id003 !name:sklearn.metrics.confusion_matrix
# TRAINING HPARS
metrics:
  f1: *id001
  acc: *id002
  cm: *id003
n_train_examples: 232  # it will be replaced in the train script
# checkpoints to average
avg_models: 10
number_of_epochs: 750 # @orion_step1: --number_of_epochs~"choices([750, 850])"
lr: 0.001
weight_decay: 0.00001
# Learning rate scheduling (cyclic learning rate is used here)
max_lr: 0.001     # Upper bound of the cycle (max value of the lr)
momentum: 0.9
base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)
step_size_multiplier: 5 #from 2 to 8
step_size: &id004 !apply:round
- 72.5
lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler
  base_lr: 0.00000001
  max_lr: 0.001
  step_size: *id004
label_smoothing: 0.0 # @orion_step1: --label_smoothing~"choices([0.0,0.1])"
loss: !name:speechbrain.nnet.losses.nll_loss
  label_smoothing: 0.0

optimizer: !name:torch.optim.Adam
  lr: 0.001
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
                                                               # epoch counter
  limit: 750
batch_size_exponent: 4
batch_size: 16
valid_ratio: 0.2

# DATA AUGMENTATION
# cutcat (disabled when min_num_segments=max_num_segments=1)
max_num_segments: 3
cutcat: &id007 !new:speechbrain.augment.time_domain.CutCat
  min_num_segments: 2
  max_num_segments: 3
# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)
amp_delta: 0.01742
rand_amp: &id008 !new:speechbrain.augment.time_domain.RandAmp
  amp_low: 0.98258
  amp_high: 1.01742
# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)
shift_delta_: 1
shift_delta: 0.01
min_shift: &id005 !apply:math.floor
- -1.25
max_shift: &id006 !apply:math.floor
- 1.25
time_shift: &id009 !new:speechbrain.augment.freq_domain.RandomShift
  min_shift: *id005
  max_shift: *id006
  dim: 1
# injection of gaussian white noise
snr_white_low: 15.0
snr_white_delta: 19.1
snr_white_high: 34.1
add_noise_white: &id010 !new:speechbrain.augment.time_domain.AddNoise
  snr_low: 15.0
  snr_high: 34.1

repeat_augment: 1 # @orion_step1: --repeat_augment 0
augment: !new:speechbrain.augment.augmenter.Augmenter
  parallel_augment: true
  concat_original: true
  parallel_augment_fixed_bs: true
  repeat_augment: 1
  shuffle_augmentations: true
  min_augmentations: 4
  max_augmentations: 4
  augmentations: [*id007, *id008, *id009, *id010]

# DATA NORMALIZATION
dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)
normalize: !name:speechbrain.processing.signal_processing.mean_std_norm
  dims: 1
# MODEL
input_shape: &id011 [null, 500, 17, null]
cnn_poolsize_: 5
cnn_poolstride_: 6
# pool size / stride from 4/125 ms to 40/125 ms = circa 30 ms
cnn_poolsize: 20                       # same resolution as for EEGNet research space
cnn_poolstride: 24                         # same resolution as for EEGNet research space
dropout: 0.07959
cnn_spatial_kernels: 64 # @orion_step1: --cnn_temporal_kernelsize~"choices([8, 32, 61, 64])"
cnn_pool_type: avg
cnn_activation_type: relu
cnn_temporal_kernels: 61 # @orion_step1: --cnn_temporal_kernels~"choices([8, 32, 64, 61])"
cnn_temporal_kernelsize: 51 # @orion_step1: --cnn_temporal_kernelsize~"choices([41, 55, 61, 63])"

model: !new:models.LSTMEEG.LSTMEEG
  input_shape: *id011
  cnn_temporal_kernels: 61
  cnn_spatial_kernels: 64
  cnn_temporal_kernelsize: [51, 1]
  cnn_poolsize: [20, 1]
  cnn_poolstride: [24, 1]
  cnn_pool_type: avg
  cnn_dropout: 0.07959
  cnn_activation_type: relu
  dense_n_neurons: 4
